{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Create scraping functions\n",
    "\n",
    "### The below codes are to make 2 dataframes for our Data Analytics submission\n",
    "#### The first function scrape restaurant features such as user rating, number of ratings, address and a few keywords specified on netpincer\n",
    "#### The second function collects information a restaurant's products and their corresponding prices as advertised on the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_base = 'https://www.netpincer.hu/'\n",
    "\n",
    "\n",
    "#create empty lists+dataframes to enrich with user defined functions\n",
    "link_list=[]\n",
    "final_df = pd.DataFrame(columns = ['Restaurant', 'Product_Name', 'Price']) \n",
    "restaurant_df = pd.DataFrame(columns = ['Restaurant', 'User-Rating',  'No-Ratings', 'Address', 'Feature1'\n",
    "                                       , 'Feature2','Feature3', 'Feature4', 'Feature5']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse netpincer to get list of html links for restaurants available at BASE_URL\n",
    "\n",
    "def generate_restaurant_links(URL):\n",
    "    global link_base\n",
    "    response = requests.get(URL)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") \n",
    "    restaurants = soup.find('ul', {'class':'vendor-list'}).findAll('a')\n",
    "    link_list.append([link_base+link.get('href') for link in restaurants])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_scraper(URL):\n",
    "    \n",
    "    global restaurant_df\n",
    "    response = requests.get(URL)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") \n",
    "\n",
    "    #Getting name of the restaurant\n",
    "    restaurant = soup.find('div',{'class':'vendor-info-main-headline item'}).getText()\n",
    "\n",
    "    #Getting features of restaurant\n",
    "    features = soup.find('ul',{'class':'vendor-info-main-details-cuisines'}).findAll('li')\n",
    "    features_list = [values.getText() for values in features[1:]]\n",
    "    #Adding nan values if feature is missing - the max amount of restaurant features are 5\n",
    "    features_list.extend((5- len(features_list)) * [np.nan])\n",
    "\n",
    "    #Getting ratings of restaurants if available \n",
    "    ratings = soup.find('div',{'class':'ratings-component'}).findAll('span')\n",
    "    ratings_list = [values.getText().split()for values in ratings[1:]]\n",
    "        #Splitting out user rating out of how many\n",
    "    ratings_list = [nums[0].split('/') for nums in ratings_list]\n",
    "        #Breaking out lists in lists\n",
    "    ratings_list = [[item] for sub_list in ratings_list for item in sub_list]\n",
    "\n",
    "    #Getting the address of a Restaurant\n",
    "    address = soup.find('p',{'class':'vendor-location'}).getText()\n",
    "\n",
    "    #Putting all of the above in a dictionary\n",
    "    dict_for_restaurant_df = {'Restaurant': restaurant, 'User-Rating':ratings_list[0][0],  'No-Ratings': ratings_list[2][0]\n",
    "                              , 'Address' : address, 'Feature1': features_list[0], 'Feature2': features_list[1]\n",
    "                              ,'Feature3': features_list[2], 'Feature4' : features_list[3],'Feature5': features_list[4]}\n",
    "\n",
    "    #Add to restaurant_df\n",
    "    restaurant_df = restaurant_df.append(dict_for_restaurant_df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_scraper (URL): \n",
    "    global final_df\n",
    "    prices = []\n",
    "    \n",
    "    response = requests.get(URL)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") \n",
    "\n",
    "    #Getting name of the restaurant\n",
    "    restaurant = soup.find('div',{'class':'vendor-info-main-headline item'}).getText()\n",
    "\n",
    "    #Getting name of product and prices - fortunately both are spans\n",
    "    smaller_soup = soup.find('div', {'class':'menu__items'}).findAll('span')\n",
    "    temp_list= [elem.getText() for elem in smaller_soup]\n",
    "\n",
    "    #Name will be every first, price will be every second element in smaller soup\n",
    "    product_names = temp_list[::2]\n",
    "    prices_temp = temp_list[1::2]\n",
    "    restaurant_name = [restaurant for i in range(len(product_names))]\n",
    "\n",
    "    #Price requires further alterations\n",
    "    for elem in prices_temp:\n",
    "        temp_elem = elem.split()\n",
    "        prices.append(\"\".join(temp_elem))\n",
    "\n",
    "    #Put vectors into pandas dataframe    \n",
    "    dict_for_df = {'Restaurant': restaurant_name, 'Product_Name': product_names, 'Price': prices}  \n",
    "    df = pd.DataFrame(dict_for_df)\n",
    "    \n",
    "    final_df = final_df.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Scrape restaurants\n",
    "\n",
    "### We scrape data and structre them in tidy data tables\n",
    "####  We first decide on the population of resturants to include - and their netpincer URLs:\n",
    "##### - Pizzaplaces that deliver to CEU\n",
    "##### - Pizzaplaces that can deliver to the city centers of the top five Hungarian cities (excluding Budapest): Debrecen, Szeged, Miskolc, Pecs, Gyor\n",
    "#### Then we run both restaurant and product scrapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEU_URL = 'https://www.netpincer.hu/restaurants/new?lat=47.501185&lng=19.049364&vertical=restaurants&cuisines=52'\n",
    "DB_URL = 'https://www.netpincer.hu/restaurants/new?lat=47.5313352&lng=21.624532&vertical=restaurants&cuisines=52'\n",
    "SZG_URL = 'https://www.netpincer.hu/restaurants/new?lat=46.254233&lng=20.1493499&vertical=restaurants&cuisines=52'\n",
    "MS_URL = 'https://www.netpincer.hu/restaurants/new?lat=48.10137599999999&lng=20.7306244&vertical=restaurants&cuisines=52'\n",
    "PCS_URL = 'https://www.netpincer.hu/restaurants/new?lat=46.07605239999999&lng=18.2282426&vertical=restaurants&cuisines=52'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv(r'C:\\Users\\T450s\\Python_directory\\trial_netpincer.csv', \n",
    "#                           index = True, sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
